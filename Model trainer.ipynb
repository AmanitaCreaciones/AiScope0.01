{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image , ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_train(dir_img_True = '../data pre processing/croped data/malaria/',dir_img_False = '../data pre processing/croped data/no malaria/', weights_file = './model_weights.h5' ,   batch_size = 128 , num_classes = 2 , epochs = 150 , img_rows = 40 , img_cols = 40 ):\n",
    "\n",
    "    malaria = []\n",
    "    no_malaria = []\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    # Open images into an array and preprocess them\n",
    "    # Load malaria\n",
    "    for file in os.listdir(dir_img_True):\n",
    "\n",
    "        if file.endswith('.jpg'):\n",
    "            #pre process images\n",
    "            img = mpimg.pil_to_array(Image.open(dir_img_True+file))\n",
    "            if img.shape[0] == 40 and img.shape[1] == 40:\n",
    "                malaria.append([img[:,:,0].reshape(40,40,-1)])\n",
    "    \n",
    "    # Load no malaria\n",
    "    for file in os.listdir(dir_img_False):\n",
    "        if file.endswith('.jpg'):\n",
    "            #pre process images\n",
    "            img = mpimg.pil_to_array(Image.open(dir_img_False+file))\n",
    "            if img.shape[0] == 40 and img.shape[1] == 40:\n",
    "                no_malaria.append([img[:,:,0].reshape(40,40,-1)])   \n",
    "    \n",
    "    # Image preprocessing to array\n",
    "    malaria = np.asarray(malaria)\n",
    "    no_malaria = np.asarray(no_malaria)\n",
    "    malaria = malaria.reshape(malaria.shape[0],40,40,-1)\n",
    "    no_malaria = no_malaria.reshape(no_malaria.shape[0],40,40,-1)\n",
    "    malaria_y = np.ones((malaria.shape[0],1)).reshape(malaria.shape[0],)\n",
    "    no_malaria_y = np.zeros((no_malaria.shape[0],1)).reshape(no_malaria.shape[0],)\n",
    "    dataset_x = np.concatenate((malaria, no_malaria), axis=0)\n",
    "    dataset_y = np.concatenate((malaria_y, no_malaria_y), axis=0)\n",
    "\n",
    "    # Split into test and train\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y, test_size=0.33, random_state=42)\n",
    "\n",
    "    #actual train on CNN\n",
    "\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # Definition of the CNN\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))  # Anterior 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Training\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "                                                \n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])                                            \n",
    "\n",
    "\n",
    "    # save weights \n",
    "    model.save_weights(weights_file+'.h5')\n",
    "    json_string = model.to_json()\n",
    "    with open(weights_file+'.json', 'w') as jsonfile:\n",
    "        jsonfile.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8524 samples, validate on 4199 samples\n",
      "Epoch 1/150\n",
      "8524/8524 [==============================] - 48s - loss: 0.7019 - acc: 0.5614 - val_loss: 0.6623 - val_acc: 0.6159\n",
      "Epoch 2/150\n",
      "8524/8524 [==============================] - 62s - loss: 0.6033 - acc: 0.6479 - val_loss: 0.4959 - val_acc: 0.7511\n",
      "Epoch 3/150\n",
      "8524/8524 [==============================] - 55s - loss: 0.5116 - acc: 0.7437 - val_loss: 0.4536 - val_acc: 0.7873\n",
      "Epoch 4/150\n",
      "8524/8524 [==============================] - 54s - loss: 0.4377 - acc: 0.8030 - val_loss: 0.4070 - val_acc: 0.8200\n",
      "Epoch 5/150\n",
      "8524/8524 [==============================] - 54s - loss: 0.4050 - acc: 0.8192 - val_loss: 0.3916 - val_acc: 0.8288\n",
      "Epoch 6/150\n",
      "8524/8524 [==============================] - 53s - loss: 0.3911 - acc: 0.8268 - val_loss: 0.3807 - val_acc: 0.8335\n",
      "Epoch 7/150\n",
      "8524/8524 [==============================] - 53s - loss: 0.3813 - acc: 0.8314 - val_loss: 0.4186 - val_acc: 0.7933\n",
      "Epoch 8/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3779 - acc: 0.8311 - val_loss: 0.3762 - val_acc: 0.8335\n",
      "Epoch 9/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3709 - acc: 0.8361 - val_loss: 0.3708 - val_acc: 0.8364\n",
      "Epoch 10/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3683 - acc: 0.8396 - val_loss: 0.3720 - val_acc: 0.8276\n",
      "Epoch 11/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3629 - acc: 0.8410 - val_loss: 0.3710 - val_acc: 0.8423\n",
      "Epoch 12/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3582 - acc: 0.8430 - val_loss: 0.3643 - val_acc: 0.8373\n",
      "Epoch 13/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3566 - acc: 0.8410 - val_loss: 0.3685 - val_acc: 0.8390\n",
      "Epoch 14/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3523 - acc: 0.8470 - val_loss: 0.3712 - val_acc: 0.8323\n",
      "Epoch 15/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3506 - acc: 0.8474 - val_loss: 0.3567 - val_acc: 0.8428\n",
      "Epoch 16/150\n",
      "8524/8524 [==============================] - 47s - loss: 0.3477 - acc: 0.8487 - val_loss: 0.3535 - val_acc: 0.8423\n",
      "Epoch 17/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3407 - acc: 0.8505 - val_loss: 0.3639 - val_acc: 0.8352\n",
      "Epoch 18/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3406 - acc: 0.8515 - val_loss: 0.3536 - val_acc: 0.8481\n",
      "Epoch 19/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3334 - acc: 0.8545 - val_loss: 0.3409 - val_acc: 0.8492\n",
      "Epoch 20/150\n",
      "8524/8524 [==============================] - 47s - loss: 0.3344 - acc: 0.8546 - val_loss: 0.3408 - val_acc: 0.8500\n",
      "Epoch 21/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3273 - acc: 0.8545 - val_loss: 0.3470 - val_acc: 0.8421\n",
      "Epoch 22/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3223 - acc: 0.8593 - val_loss: 0.3317 - val_acc: 0.8481\n",
      "Epoch 23/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3180 - acc: 0.8605 - val_loss: 0.3450 - val_acc: 0.8435\n",
      "Epoch 24/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3166 - acc: 0.8582 - val_loss: 0.3317 - val_acc: 0.8540\n",
      "Epoch 25/150\n",
      "8524/8524 [==============================] - 44s - loss: 0.3097 - acc: 0.8661 - val_loss: 0.3502 - val_acc: 0.8426\n",
      "Epoch 26/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3082 - acc: 0.8643 - val_loss: 0.3252 - val_acc: 0.8540\n",
      "Epoch 27/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3058 - acc: 0.8672 - val_loss: 0.3246 - val_acc: 0.8559\n",
      "Epoch 28/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.3035 - acc: 0.8691 - val_loss: 0.3382 - val_acc: 0.8483\n",
      "Epoch 29/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.3004 - acc: 0.8706 - val_loss: 0.3294 - val_acc: 0.8481\n",
      "Epoch 30/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2976 - acc: 0.8710 - val_loss: 0.3202 - val_acc: 0.8578\n",
      "Epoch 31/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2910 - acc: 0.8735 - val_loss: 0.3196 - val_acc: 0.8547\n",
      "Epoch 32/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2895 - acc: 0.8748 - val_loss: 0.3166 - val_acc: 0.8569\n",
      "Epoch 33/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2858 - acc: 0.8758 - val_loss: 0.3211 - val_acc: 0.8595\n",
      "Epoch 34/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2844 - acc: 0.8774 - val_loss: 0.3148 - val_acc: 0.8554\n",
      "Epoch 35/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2803 - acc: 0.8789 - val_loss: 0.3193 - val_acc: 0.8573\n",
      "Epoch 36/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2798 - acc: 0.8799 - val_loss: 0.3194 - val_acc: 0.8521\n",
      "Epoch 37/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2726 - acc: 0.8837 - val_loss: 0.3130 - val_acc: 0.8566\n",
      "Epoch 38/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2749 - acc: 0.8820 - val_loss: 0.3179 - val_acc: 0.8562\n",
      "Epoch 39/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2705 - acc: 0.8842 - val_loss: 0.3227 - val_acc: 0.8550\n",
      "Epoch 40/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2633 - acc: 0.8895 - val_loss: 0.3238 - val_acc: 0.8562\n",
      "Epoch 41/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2662 - acc: 0.8844 - val_loss: 0.3172 - val_acc: 0.8573\n",
      "Epoch 42/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2613 - acc: 0.8887 - val_loss: 0.3094 - val_acc: 0.8564\n",
      "Epoch 43/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2588 - acc: 0.8918 - val_loss: 0.3089 - val_acc: 0.8588\n",
      "Epoch 44/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2581 - acc: 0.8918 - val_loss: 0.3134 - val_acc: 0.8571\n",
      "Epoch 45/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2568 - acc: 0.8935 - val_loss: 0.3144 - val_acc: 0.8614\n",
      "Epoch 46/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2531 - acc: 0.8948 - val_loss: 0.3115 - val_acc: 0.8607\n",
      "Epoch 47/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2497 - acc: 0.8921 - val_loss: 0.3137 - val_acc: 0.8621\n",
      "Epoch 48/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2460 - acc: 0.8979 - val_loss: 0.3076 - val_acc: 0.8633\n",
      "Epoch 49/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2473 - acc: 0.8966 - val_loss: 0.3098 - val_acc: 0.8597\n",
      "Epoch 50/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2418 - acc: 0.8965 - val_loss: 0.3259 - val_acc: 0.8488\n",
      "Epoch 51/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2418 - acc: 0.8961 - val_loss: 0.3241 - val_acc: 0.8547\n",
      "Epoch 52/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2387 - acc: 0.8997 - val_loss: 0.3086 - val_acc: 0.8619\n",
      "Epoch 53/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2361 - acc: 0.9023 - val_loss: 0.3071 - val_acc: 0.8616\n",
      "Epoch 54/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2355 - acc: 0.9034 - val_loss: 0.3051 - val_acc: 0.8614\n",
      "Epoch 55/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2304 - acc: 0.9036 - val_loss: 0.3215 - val_acc: 0.8514\n",
      "Epoch 56/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2310 - acc: 0.9024 - val_loss: 0.3119 - val_acc: 0.8612\n",
      "Epoch 57/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.2249 - acc: 0.9078 - val_loss: 0.3097 - val_acc: 0.8631\n",
      "Epoch 58/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2245 - acc: 0.9070 - val_loss: 0.3168 - val_acc: 0.8595\n",
      "Epoch 59/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2252 - acc: 0.9057 - val_loss: 0.3145 - val_acc: 0.8623\n",
      "Epoch 60/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2184 - acc: 0.9106 - val_loss: 0.3109 - val_acc: 0.8643\n",
      "Epoch 61/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2141 - acc: 0.9141 - val_loss: 0.3148 - val_acc: 0.8619\n",
      "Epoch 62/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2151 - acc: 0.9120 - val_loss: 0.3095 - val_acc: 0.8633\n",
      "Epoch 63/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2096 - acc: 0.9130 - val_loss: 0.3143 - val_acc: 0.8616\n",
      "Epoch 64/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2098 - acc: 0.9128 - val_loss: 0.3132 - val_acc: 0.8650\n",
      "Epoch 65/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2054 - acc: 0.9164 - val_loss: 0.4001 - val_acc: 0.8276\n",
      "Epoch 66/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.2064 - acc: 0.9142 - val_loss: 0.3204 - val_acc: 0.8626\n",
      "Epoch 67/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.1979 - acc: 0.9202 - val_loss: 0.3149 - val_acc: 0.8650\n",
      "Epoch 68/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1988 - acc: 0.9206 - val_loss: 0.3147 - val_acc: 0.8666\n",
      "Epoch 69/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1952 - acc: 0.9226 - val_loss: 0.3178 - val_acc: 0.8659\n",
      "Epoch 70/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.1942 - acc: 0.9206 - val_loss: 0.3254 - val_acc: 0.8597\n",
      "Epoch 71/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1931 - acc: 0.9218 - val_loss: 0.3164 - val_acc: 0.8662\n",
      "Epoch 72/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.1861 - acc: 0.9261 - val_loss: 0.3161 - val_acc: 0.8650\n",
      "Epoch 73/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1889 - acc: 0.9240 - val_loss: 0.3186 - val_acc: 0.8669\n",
      "Epoch 74/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1828 - acc: 0.9240 - val_loss: 0.3367 - val_acc: 0.8588\n",
      "Epoch 75/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1803 - acc: 0.9262 - val_loss: 0.3201 - val_acc: 0.8650\n",
      "Epoch 76/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1764 - acc: 0.9303 - val_loss: 0.3229 - val_acc: 0.8669\n",
      "Epoch 77/150\n",
      "8524/8524 [==============================] - 49s - loss: 0.1733 - acc: 0.9313 - val_loss: 0.3158 - val_acc: 0.8709\n",
      "Epoch 78/150\n",
      "8524/8524 [==============================] - 50s - loss: 0.1723 - acc: 0.9302 - val_loss: 0.3263 - val_acc: 0.8704\n",
      "Epoch 79/150\n",
      "2432/8524 [=======>......................] - ETA: 31s - loss: 0.1678 - acc: 0.9359"
     ]
    }
   ],
   "source": [
    "model_train(weights_file = './model_weights-test',batch_size = 128 , epochs = 150 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "weight list:\n",
    "\n",
    "model_weights <- plane images first model\n",
    "Test accuracy:0.98\n",
    "\n",
    "model_weights-1 <- plane images first model dense layer 128 batch size 1000 150 epochs\n",
    "30s por epoch\n",
    "Test loss: 0.16379118345\n",
    "Test accuracy: 0.938775510204\n",
    "\n",
    "model_weights-2 <- plane images first model dense layer 500 batch size 1000 150 epochs\n",
    "40s por epoch\n",
    "Test loss: 0.123215783985\n",
    "Test accuracy: 0.956977385549\n",
    "\n",
    "model_weights-3 <- plane images first model dense layer 500 batch size a 128 150 epochs\n",
    "45s per epoch\n",
    "Test loss: 0.118130825795\n",
    "Test accuracy: 0.975730832874\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))  # Anterior 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_weights-4 <-  with croped errors 150 epochs 1000 bach size\n",
    "86s per epoch\n",
    "Test loss: 0.548020246369\n",
    "Test accuracy: 0.829737205987\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))  # Anterior 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    \n",
    "model_weights-5 <- malaria (only croped) no malaria (croped and corrected) 150 epochs 128 bach size\n",
    "50s per epoch  \n",
    "Test loss: 0.468808364531\n",
    "Test accuracy: 0.873303167421\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))  # Anterior 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "Probar otro random state\n",
    "# PAra hacer pooling por enmedio\n",
    "model_weights-6 <- malaria (only croped) no malaria (croped and corrected) 150 epochs 128 bach size\n",
    "s per epoch    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))  # Anterior 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "# Probar modificando los dropouts\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
